---
  title: "Tugas Praktikum 3"
author: Diani Raras Puspita
output: html_document
date: "2025-09-04"
---
  
  
  ## Pemanggilan Packages
  
```{r}
library(dplyr)
library(TTR)
library(forecast)
library(lmtest) #digunakan untuk uji formal pendeteksian autokorelasi
library(orcutt) #untuk membuat model regresi Cochrane-Orcutt
library(HoRM) #untuk membuat model regresi Hildreth-Lu
```

# Input Data

Data yang digunakan dalam tugas ini adalah data IPM Provinsi Papua periode tahun 2010-2021.

## Data IPM Papua

```{r}
# Buat data IPM Papua
tahun <- c(2010,2011,2012,2013,2014,2015,2016,2017,
           2018,2019,2020,2021,2022,2023)

ipm <- c(54.55,55.01,55.55,56.25,56.75,
         57.25,58.05,59.09,60.06,60.84,
         61.22,61.40,62.16,63.01)

dtPapua <- cbind(tahun, ipm)
dtPapua <- as.data.frame(dtPapua)
dtPapua
```

#Eksplorasi Data
Visualisasi *plot time-series* dari IPM Provinsi Papua Periode 2010-2024

## Membentuk Objek Time Series

```{r}
# Membentuk objek time series dari data IPM Papua
dataPapua.ts <- ts(dtPapua$ipm, start = 2010, frequency = 1)
dataPapua.ts
```

## Membuat Plot Time Series

```{r}
# Membuat plot time series IPM Papua
ts.plot(dataPapua.ts,
        xlab = "Tahun",
        ylab = "IPM",
        main = "Time Series Plot of IPM Papua",
        col = "blue", lwd = 2)

# Tambahkan titik data biar lebih jelas
points(dataPapua.ts, col = "red", pch = 19)
```
Selanjutnya akan dilakukan ramalan dan pemulusan dengan metode DMA dan DES karena terlihat pada plot di atas menunjukkan adanya *trend*.

## Peramalan dengan Double Moving Average

```{r}
dt.sma <- SMA(dataPapua.ts, n=3)
dma <- SMA(dt.sma, n = 3)
At <- 2*dt.sma - dma
Bt <- 2/(3-1)*(dt.sma - dma)
dt.dma <- At+Bt
dt.ramal <- c(NA, dt.dma)

t = 1:5
f = c()

for (i in t) {
  f[i] = At[length(At)] + Bt[length(Bt)]*(i)
}
```

## Gabungan Data Aktual, Pemulusan, dan Ramalan

```{r}
dt.gab <- cbind(aktual = c(dataPapua.ts, rep(NA,5)), 
                pemulusan1 = c(dt.sma, rep(NA,5)),
                pemulusan2 = c(dt.dma, rep(NA,5)),
                At = c(At, rep(NA,5)), 
                Bt = c(Bt, rep(NA,5)),
                ramalan = c(dt.ramal, f[-1]))
dt.gab

# Plot time series
ts.plot(dt.gab[,1], xlab="Time Period ", ylab="IPM", 
        main= "DMA N=3 Data IPM Papua", ylim=c(62,75))
points(dt.gab[,1])
points(dt.gab[,3])
points(dt.gab[,6])
lines(dt.gab[,3], col="green", lwd=2)
lines(dt.gab[,6], col="red", lwd=2)
legend("topleft", c("data aktual","data pemulusan","data peramalan"), 
       lty=8, col=c("black","green","red"), cex=0.8)
```
Selanjutnya akan dilihat keakuratan dari metode DMA

## Menghitung Nilai Keakuratan

```{r}
error.dma = dataPapua.ts - dt.ramal[1:length(dataPapua.ts)]
SSE.dma = sum(error.dma[6:length(dataPapua.ts)]^2)
MSE.dma = mean(error.dma[6:length(dataPapua.ts)]^2)
MAPE.dma = mean(abs((error.dma[6:length(dataPapua.ts)]/dataPapua.ts[6:length(dataPapua.ts)])*100))

akurasi.dma <- matrix(c(SSE.dma, MSE.dma, MAPE.dma))
row.names(akurasi.dma) <- c("SSE", "MSE", "MAPE")
colnames(akurasi.dma) <- c("Akurasi m = 3")
akurasi.dma
```
Selanjutnya akan digunakan metode *Double Exponential Smoothing* dengan cara sebagai berikut.

Pertama akan data akan dibagi menjadi data *training* dan data *testing*.

## Membagi Data Training dan Testing

```{r}
# Membagi training (10 data pertama) dan testing (sisa 4 data)
training <- dtPapua[1:10, 2]
testing  <- dtPapua[11:14, 2]

# Data time series
training.ts <- ts(training)
testing.ts  <- ts(testing, start = 11)

# Eksplorasi data
plot(dataPapua.ts, col="red", main="Plot semua data")
points(dataPapua.ts)

plot(training.ts, col="blue", main="Plot data training")
points(training.ts)
```
Selanjutnya akan dilakukan pemulusan dengan DES, kali ini langsung dicari lambda dan gamma optimum sebagai berikut. Nilai lambda dan gamma optimum dapat dilihat pada smoothing parameters alpha untuk nilai lambda dan beta untuk nilai gamma.

## Model Holt-Winters pada Data Training Papua

```{r}
# Lamda dan gamma optimum
des.opt <- HoltWinters(training.ts, gamma = FALSE)
des.opt
plot(des.opt)
legend("topleft", c("Data Aktual", "Peramalan"), col = c("black", "red"), 
       lty = c(1,1))

# Ramalan
ramalandesopt <- forecast(des.opt, h=5)
ramalandesopt
```
Selanjutnya akan dicari akurasi dari metode DES.

## Akurasi Model Holt-Winters (λ dan γ optimum)

```{r}
ssedes.train <- des.opt$SSE
msedes.train <- ssedes.train/length(training.ts)
sisaandes <- ramalandesopt$residuals
head(sisaandes)

mapedes.train <- sum(abs(sisaandes[3:length(training.ts)]/training.ts[3:length(training.ts)])*100)/length(training.ts)

akurasides.opt <- matrix(c(ssedes.train, msedes.train, mapedes.train))
row.names(akurasides.opt) <- c("SSE", "MSE", "MAPE")
colnames(akurasides.opt) <- c("Akurasi lamda dan gamma optimum")
akurasides.opt
```
## Akurasi Data Testing Holt-Winters (λ dan γ optimum)

```{r}
#Akurasi data testing
selisihdesopt <- ramalandesopt$mean - testing.ts
selisihdesopt

SSEtestingdesopt <- sum(selisihdesopt^2)
SSEtestingdesopt <- SSEtestingdesopt/length(testing.ts)
MAPEtestingdesopt <- sum(abs(selisihdesopt/testing.ts)*100)/length(testing.ts)

akurasiDesTesting <- matrix(c(SSEtestingdesopt, SSEtestingdesopt, MAPEtestingdesopt))
row.names(akurasiDesTesting) <- c("SSE", "MSE", "MAPE")
colnames(akurasiDesTesting) <- c("Akurasi lamda dan gamma optimum")
akurasiDesTesting
```
Setelah didapatkan nilai akurasi untuk metode DMA dan DES, selanjutnya akan dibandingkan keakuratan antar metode keduanya.

```{r}
cbind(akurasi.dma, akurasides.opt)
```
## Kesimpulan

Berdasarkan hasil perbandingan akurasi, diperoleh bahwa nilai **SSE, MSE, dan MAPE pada metode DES (lamda dan gamma optimum)** lebih kecil dibandingkan dengan metode **DMA (m = 3)**, yaitu:  
  
  - **SSE**: 2.0491 (DMA) vs 0.2606 (DES)  
- **MSE**: 0.2277 (DMA) vs 0.0261 (DES)  
- **MAPE**: 0.6231 (DMA) vs 0.2133 (DES)  

Dengan demikian, metode peramalan dan pemulusan terbaik antara keduanya adalah **metode DES**, karena memberikan tingkat kesalahan yang lebih kecil.

Setelah melakukan peramalan, data yang telah dimasukkan kemudian dieksplorasi. Eksplorasi pertama yang dilakukan adalah dengan menggunakan *scatter plot*.

## Eksplorasi Data

### Scatter Plot Tahun vs Nilai IPM Papua

```{r}
# Pembuatan Scatter Plot
plot(dtPapua$tahun, dtPapua$ipm, pch = 20, col = "blue",
     main = "Scatter Plot Tahun vs Nilai IPM Papua",
     xlab = "Tahun",
     ylab = "Nilai IPM")

# Menampilkan Nilai Korelasi
cor(dtPapua$tahun, dtPapua$ipm)
```
Berdasarkan scatter plot di atas, terlihat adanya hubungan / korelasi positif antara peubah tahun dengan nilai IPM, terlihat titik-titik pada plot yang naik ke arah kanan atas. Hal tersebut juga diperkuat dengan hasil perhitungan aplikasi `R` di mana didapatkan nilai korelasi sebesar $0.9954442$.

Setelah mengetahui adanya hubungan antar dua peubah, maka model regresi dapat ditentukan.


## Pembuatan Model Regresi Linear IPM Papua

```{r}
#Pembuatan Model Regresi
#model regresi
model<- lm(ipm~tahun, data = dtPapua)
summary(model)
```
## Kesimpulan Regresi Linear

Model yang dihasilkan adalah:
  
  $$y_t = -1297 + 0.6725x_t$$
  
  Berdasarkan ringkasan model dapat diketahui bahwa hasil uji F memiliki *p-value* \< $\alpha$ (5%).  
Artinya, minimal terdapat satu variabel yang berpengaruh nyata terhadap model.  

Hasil uji-t parsial kedua parameter regresi, yaitu intersep dan koefisien regresi, juga menunjukkan hal yang sama, yaitu memiliki *p-value* \< $\alpha$ (5%) sehingga nyata dalam taraf 5%.Selanjutnya dapat dilihat juga nilai $R^2 = 0.9909$.Artinya, sebesar 99.09% keragaman nilai IPM Papua dapat dijelaskan oleh peubah tahun.  Hasil ini menunjukkan bahwa model regresi linear sederhana yang diperoleh sangat baik dalam menjelaskan variasi IPM Papua. Namun, langkah selanjutnya perlu dilakukan uji terhadap sisaan untuk memastikan asumsi klasik regresi terpenuhi.

## Diagnostik Regresi
                                                                                 
```{r}
# Sisaan dan fitted value
sisaan <- residuals(model)
fitValue <- predict(model)
# Diagnostik dengan eksploratif
par(mfrow = c(2,2))

# QQ Plot
qqnorm(sisaan)
qqline(sisaan, col = "steelblue", lwd = 2)

# Sisaan vs Fitted Values
plot(fitValue, sisaan, col = "steelblue", pch = 20,
     xlab = "Fitted Values", ylab = "Sisaan",
     main = "Sisaan vs Fitted Values")
abline(a = 0, b = 0, lwd = 2)

# Histogram sisaan
hist(sisaan, col = "steelblue")

# Sisaan vs Order
plot(seq(1, length(sisaan), 1), sisaan, col = "steelblue", pch = 20,
     xlab = "Order", ylab = "Sisaan",
     main = "Sisaan vs Order")
lines(seq(1, length(sisaan), 1), sisaan, col = "red")
abline(a = 0, b = 0, lwd = 2)
```
                                                                              
Dua plot di samping kiri digunakan untuk melihat apakah sisaan menyebar normal. Normal Q-Q Plot di atas menunjukkan bahwa titik-titik sisaan cukup mendekati garis lurus, sehingga dapat dikatakan sisaan cenderung menyebar normal. Namun, histogram dari sisaan terlihat agak menyebar rata dan tidak terlalu jelas membentuk pola distribusi normal. Selanjutnya, dua plot di samping kanan digunakan untuk melihat autokorelasi. Plot Sisaan vs Fitted Values menunjukkan bahwa sisaan menyebar cukup merata di sekitar garis nol tanpa pola tertentu, sehingga tidak ada indikasi kuat terjadinya heteroskedastisitas. Namun, untuk memastikannya perlu uji formal. Secara umum, hasil diagnostik awal menunjukkan bahwa asumsi normalitas relatif terpenuhi, sementara autokorelasi belum dapat dipastikan dan perlu diuji lebih lanjut menggunakan plot ACF dan PACF.
                                                                                                                                                         
```{r}                                                                    
#Melihat Sisaan Menyebar Normal/Tidak
#H0: sisaan mengikuti sebaran normal
#H1: sisaan tidak mengikuti sebaran normal
shapiro.test(sisaan)
```                                                                                                                                                         
                                                                                                                                                         Berdasarkan hasil uji formal **Shapiro-Wilk** dan **Kolmogorov-Smirnov**, didapatkan nilai *p-value* masing-masing sebesar 0.7934 dan 0.9672, keduanya lebih besar dari \$\alpha = 0.05\$. Artinya, terdapat cukup bukti untuk menyatakan bahwa sisaan berdistribusi normal.
                                                                                 
                                                                                                                                                                
```{r}
# Residual dari model linear IPM ~ Tahun
model <- lm(ipm ~ tahun, data=dtPapua)                                           residuals_model <- residuals(model)
# ACF dan PACF untuk identifikasi autokorelasi
par(mfrow = c(1,2))
acf(residuals_model, main="ACF Residuals")
pacf(residuals_model, main="PACF Residuals")
```
                                                                                                                                                         Berdasarkan plot ACF dan PACF residual IPM Papua 2010–2024:
- Pada plot ACF, sebagian besar lag berada di dalam batas signifikan (garis putus-putus), hanya beberapa lag kecil mendekati batas tetapi tidak tampak jelas signifikan.
- Pada plot PACF, semua lag juga berada di dalam batas signifikan.
Kesimpulan: Berdasarkan plot ACF dan PACF, terlihat sebagian besar lag berada dalam rentang batas dan tidak ada lag yang jelas signifikan. Namun, untuk memastikan ada tidaknya autokorelasi, perlu dilakukan uji formal, misalnya uji Durbin-Watson.

```{r}                                                                    
#Deteksi autokorelasi dengan uji-Durbin Watson
#H0: tidak ada autokorelasi
#H1: ada autokorelasi
dwtest(model)
```                                                                                                                                                                       
Berdasarkan hasil DW Test, didapatkan nilai $DW = 0.78568$ dan *p-value* = $0.00116$. Berdasarkan tabel Durbin-Watson diperoleh nilai $DL = 1.0450$ dan $DU = 1.3503$. Berdasarkan hasil uji Durbin-Watson: residual model menunjukkan adanya autokorelasi positif yang signifikan. Artinya, nilai residual pada satu observasi cenderung berkorelasi positif dengan residual observasi sebelumnya, sehingga model regresi mungkin tidak sepenuhnya memenuhi asumsi independensi residual. Begitu pula, dengan nilai *p-value* \< 0.05 dapat disimpulkan bahwa tolak H0 bukti mengatakan adanya autokorelasi. Oleh karena itu, selanjutnya diperlukan penangan autokorelasi. Penanganan yang akan digunakan menggunakan dua metode, yaitu Cochrane-Orcutt dan Hildret-Lu.
                                                                                 # Penanganan Autokorelasi
                                                                                 ## Metode Cochrane-Orcutt
Penanganan metode Cochrane-Orcutt dapat dilakukan dengan bantuan packages Orcutt pada aplikasi `R` maupun secara manual. Berikut ini ditampilkan cara menggunakan bantuan `library` *packages* `Orcutt`.


```{r}
#Penanganan Autokorelasi Cochrane-Orcutt
modelCO<-cochrane.orcutt(model)
modelCO
```

Kesimpulan Hasil Model Cochrane-Orcutt
Hasil keluaran model setelah dilakukan penanganan adalah sebagai berikut:
$$\hat{y}_i = -1343.402307 + 0.695248x_t$$
Hasil juga menunjukkan bahwa nilai Durbin-Watson (DW) dan *p-value* meningkat menjadi **1.06925** dan **0.01228**. Namun, nilai DW tersebut masih berada di bawah batas bawah (\(DW < DL = 1.0450\)) sehingga menunjukkan adanya indikasi autokorelasi positif. Hal ini juga didukung dengan nilai *p-value* < 0.05, artinya terdapat menyatakan bahwa sisaan masih mengalami autokorelasi .
                                                                                 Untuk nilai \(\hat{\rho}\)  optimum yang digunakan adalah **0.569137**. Nilai tersebut dapat diketahui dengan *syntax* berikut:
                                                                                 

```{r}
#Rho optimum
rho<- modelCO$rho
rho
```
Selanjutnya akan dilakukan transformasi secara manual dengan syntax berikut ini.

```{r}
ipm
```
```{r}
ipm[-1]
```
```{r}
#Transformasi Manual
ipm.trans<- ipm[-1]-ipm[-12]*rho
tahun.trans<- tahun[-1]-tahun[-12]*rho
modelCOmanual<- lm(ipm.trans~tahun.trans)
summary(modelCOmanual)
```
Hasil model transformasi bukan merupakan model sesungguhnya. Koefisien regresi masih perlu dicari kembali mengikuti $β_0^*=β_0+ρ ̂β_0$ dan $β_1^*=β_1$.

```{r}
#Mencari Penduga Koefisien Regresi setelah Transformasi ke Persamaan Awal
b0bintang <- modelCOmanual$coefficients[-2]
b0 <- b0bintang/(1-rho)
b1 <- modelCOmanual$coefficients[-1]
b0
b1
```

## Metode Hildreth-Lu

Penanganan kedua adalah menggunakan metode Hildreth-Lu. Metode ini akan mencari nilai SSE terkecil dan dapat dicari secara manual maupun menggunakan packages. Jika menggunakan packages, gunakan `library` *packages* `HORM`.

```{r}
library(HoRM)

# ambil y dan x (satu prediktor saja)
y <- dtPapua$ipm
x <- dtPapua$tahun

# grid search rho 0–0.9
r <- seq(0, 0.9, by = 0.1)
tab <- data.frame(
  rho = r,
  SSE = sapply(r, function(rr) deviance(hildreth.lu(y, x, rr)))
)

tab            # tabel rho vs SSE
rho_hat <- tab$rho[which.min(tab$SSE)]   # rho terbaik
fit_hl  <- hildreth.lu(y, x, rho_hat)    # model final
summary(fit_hl)

```
```{r}
#Penanganan Autokorelasi Hildreth lu
# Hildreth-Lu
hildreth.lu.func<- function(r, model){
  x <- model.matrix(model)[,-1]
  y <- model.response(model.frame(model))
  n <- length(y)
  t <- 2:n
  y <- y[t]-r*y[t-1]
  x <- x[t]-r*x[t-1]
  
  return(lm(y~x))
}

#Pencarian rho yang meminimumkan SSE
r <- c(seq(0.1,0.9, by= 0.1))
tab <- data.frame("rho" = r, "SSE" = sapply(r, function(i){deviance(hildreth.lu.func(i, model))}))
round(tab, 4)
```

Pertama-tama akan dicari di mana kira-kira $ρ$ yang menghasilkan SSE minimum. Pada hasil di atas terlihat $ρ$ minimum ketika 0.6. Namun, hasil tersebut masih kurang teliti sehingga akan dicari kembali $ρ$ yang lebih optimum dengan ketelitian yang lebih. Jika sebelumnya jarak antar $ρ$ yang dicari adalah 0.1, kali ini jarak antar $ρ$ adalah 0.001 dan dilakukan pada selang 0.2 sampai dengan 0.5.

```{r}
#Rho optimal di sekitar 0.6
rOpt <- seq(0.4,0.8, by= 0.001)
tabOpt <- data.frame("rho" = rOpt, "SSE" = sapply(rOpt, function(i){deviance(hildreth.lu.func(i, model))}))
head(tabOpt[order(tabOpt$SSE),])
```
```{r}
#Grafik SSE optimum
par(mfrow = c(1,1))
plot(tab$SSE ~ tab$rho , type = "l", xlab = "Rho", ylab = "SSE")
abline(v = tabOpt[tabOpt$SSE==min(tabOpt$SSE),"rho"], lty = 2, col="red",lwd=2)
text(x=0.569, y=0.5438896, labels = "rho=0.569", cex = 0.8)
```
Perhitungan yang dilakukan aplikasi `R` menunjukkan bahwa nilai $ρ$ optimum, yaitu saat SSE terkecil terdapat pada nilai $ρ=0.569$. Hal tersebut juga ditunjukkan pada plot. Selanjutnya, model dapat didapatkan dengan mengevaluasi nilai $ρ$ ke dalam fungsi `hildreth.lu.func`, serta dilanjutkan dengan pengujian autokorelasi dengan uji Durbin-Watson. Namun, setelah pengecekan tersebut tidak lupa koefisien regresi tersebut digunakan untuk transformasi balik. Persamaan hasil transformasi itulah yang menjadi persamaan sesungguhnya.

```{r}
# Model terbaik
modelHL <- hildreth.lu.func(0.569, model)
summary(modelHL)

# Transformasi Balik
cat("y = ", coef(modelHL)[1]/(1-0.569), " + ", coef(modelHL)[2], "x", sep = "")
```
Setelah dilakukan tranformasi balik, didapatkan model dengan metode Hildreth-Lu sebagai berikut. $$y_i=-1062.032+0.5597492x_t$$

```{r}
#Deteksi autokorelasi
dwtest(modelHL)
```
Hasil Hildreth-Lu juga menunjukkan bahwa nilai Durbin-Watson (DW) dan *p-value* meningkat menjadi **1.06925** dan **0.01228**. Namun, nilai DW tersebut masih berada di bawah batas bawah (\(DW < DL = 1.0450\)) sehingga menunjukkan adanya indikasi autokorelasi positif. Hal ini juga didukung dengan nilai *p-value* < 0.05, artinya terdapat menyatakan bahwa sisaan masih mengalami autokorelasi .

Terakhir, akan dibandingkan nilai SSE dari ketiga metode (metode awal, metode Cochrane-Orcutt, dan Hildreth-Lu).

```{r}
#Perbandingan
sseModelawal <- anova(model)$`Sum Sq`[-1]
sseModelCO <- anova(modelCOmanual)$`Sum Sq`[-1]
sseModelHL <- anova(modelHL)$`Sum Sq`[-1]
mseModelawal <- sseModelawal/length(ipm)
mseModelCO <- sseModelCO/length(ipm)
mseModelHL <- sseModelHL/length(ipm)
akurasi <- matrix(c(sseModelawal,sseModelCO,sseModelHL,
                    mseModelawal,mseModelCO,mseModelHL),nrow=2,ncol=3,byrow = T)
colnames(akurasi) <- c("Model Awal", "Model Cochrane-Orcutt", "Model Hildreth-Lu")
row.names(akurasi) <- c("SSE","MSE")
akurasi
```
Berdasarkan hasil tersebut dapat diketahui bahwa hasil penanganan autokorelasi dengan metode Cochrane-Orcutt dan Hildreth-Lu memiliki SSE yang sama, sebesar $0.54452205$ 

## Kesimpulan Hasil Model Cochrane-Orcutt dan Hildreth-Lu

Hasil keluaran model setelah dilakukan penanganan menggunakan Cochrane-Orcutt dan Hildreth-Lu adalah sebagai berikut:

$$
\hat{y}_i = \frac{\text{Intercept}}{1-\hat{\rho}} + \text{Slope} \cdot x_t
$$

Berdasarkan hasil *Cochrane-Orcutt* / *Hildreth-Lu*, nilai koefisien yang diperoleh adalah:

- Intercept: `r coef(modelHL)[1]`  
- Slope: `r coef(modelHL)[2]`  
- Rho optimum (\(\hat{\rho}\)): 0.569137  

Sehingga persamaan transformasi balik menjadi:

```{r}
cat("y = ", coef(modelHL)[1]/(1-0.569137), " + ", coef(modelHL)[2], " x_t", sep = "")
```


